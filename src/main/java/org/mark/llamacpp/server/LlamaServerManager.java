package org.mark.llamacpp.server;

import java.io.BufferedReader;
import java.io.File;
import java.io.IOException;
import java.io.InputStreamReader;
import java.io.OutputStream;
import java.net.HttpURLConnection;
import java.net.URI;
import java.net.URL;
import java.nio.charset.StandardCharsets;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.HashSet;
import java.util.LinkedHashMap;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.regex.Matcher;
import java.util.regex.Pattern;
import java.util.stream.Stream;

import org.mark.llamacpp.gguf.GGUFBundle;
import org.mark.llamacpp.gguf.GGUFMetaData;
import org.mark.llamacpp.gguf.GGUFModel;
import org.mark.llamacpp.server.struct.ApiResponse;
import org.mark.llamacpp.server.struct.ModelPathConfig;
import org.mark.llamacpp.server.struct.ModelPathDataStruct;
import org.mark.llamacpp.server.tools.CommandLineRunner;
import org.mark.llamacpp.server.tools.PortChecker;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.gson.Gson;
import com.google.gson.JsonObject;

/**
 * 	
 */
public class LlamaServerManager {
	
	/**
	 * 	
	 */
	private static final Logger LOGGER = LoggerFactory.getLogger(LlamaServerManager.class);

	/**
	 * 	
	 */
	private static final Gson gson = new Gson();
	
	/**
	 * 	
	 */
	private final ConfigManager configManager = ConfigManager.getInstance();
	
	/**
	 * 	单例
	 */
	private static final LlamaServerManager INSTANCE = new LlamaServerManager();

	/**
	 * 	获取单例
	 * @return
	 */
	public static LlamaServerManager getInstance() {
		return INSTANCE;
	}

    /**
     * 存放模型的路径（支持多个根目录）。
     */
    private List<ModelPathDataStruct> modelPaths = new ArrayList<>();
	
	
	/**
	 * 	所有GGUF模型的列表
	 */
	private List<GGUFModel> list = new LinkedList<>();
	
	/**
	 * 已加载的模型进程列表
	 */
	private Map<String, LlamaCppProcess> loadedProcesses = new LinkedHashMap<>();
	
	/**
	 * 端口计数器，用于递增分配端口
	 */
	private AtomicInteger portCounter = new AtomicInteger(8081);
	
	/**
	 * 模型ID到端口映射
	 */
	private Map<String, Integer> modelPorts = new HashMap<>();
	
	/**
	 * 	正在加载中的模型。
	 */
	private Set<String> loadingModels = new HashSet<>();
	
	/**
	 * 线程池，用于异步执行模型加载任务
	 */
	private final ExecutorService executorService = Executors.newSingleThreadExecutor();
	
	/**
	 *
	 */
	private LlamaServerManager() {
		// 尝试从配置文件加载设置
		this.loadSettingsFromFile();
	}
	
	/**
	 * 从JSON文件加载设置
	 */
    private void loadSettingsFromFile() {
        try {
			try {
				Path configFile = LlamaServer.getModelPathConfigPath();
				ModelPathConfig cfg = LlamaServer.readModelPathConfig(configFile);
				
				List<ModelPathDataStruct> paths = new ArrayList<>();
				if (cfg != null && cfg.getItems() != null) {
					for (ModelPathDataStruct item : cfg.getItems()) {
						if (item == null || item.getPath() == null) continue;
						String p = item.getPath().trim();
						if (p.isEmpty()) continue;
						// 判断路径是否存在
						paths.add(item);
					}
				}
				if (!paths.isEmpty()) {
					this.modelPaths = paths;
					return;
				}
			} catch (Exception e) {
				e.printStackTrace();
			}
		} catch (Exception e) {
			e.printStackTrace();
			System.err.println("从配置文件加载设置失败，使用默认设置: " + e.getMessage());
		}
	}

    /**
     * 	设置模型路径列表
     * @param paths
     */
    public void setModelPaths(List<ModelPathDataStruct> paths) {
        this.modelPaths = new ArrayList<>();
        if (paths != null) {
            for (ModelPathDataStruct p : paths) {
                if (p != null && !p.getPath().trim().isEmpty()) this.modelPaths.add(p);
            }
        }
    }

    /**
     * 	获取当前设定的模型路径列表
     * @return
     */
    public List<ModelPathDataStruct> getModelPaths() {
        return new ArrayList<>(this.modelPaths);
    }
	
	/**
	 * 	获取模型列表。
	 * @return
	 */
	public List<GGUFModel> listModel() {
		return this.listModel(false);
	}
	
	
	/**
	 * 	获取模型列表 
	 * @param reload 是否重新加载
	 * @return
	 */
    public List<GGUFModel> listModel(boolean reload) {
        synchronized (this.list) {
            // 如果列表是空的，就去检索
            if(this.list.size() == 0 || reload) {
                this.list.clear();
                // 新建一个临时集合
                List<ModelPathDataStruct> list = new ArrayList<>(this.modelPaths);
                // 扫描默认目录
                list.add(new ModelPathDataStruct(LlamaServer.getDefaultModelsPath(), "", ""));
                
                for (ModelPathDataStruct root : list) {
                    if (root == null || root.getPath().trim().isEmpty()) continue;
                    Path modelDir = Paths.get(root.getPath().trim());
                    if (!Files.exists(modelDir) || !Files.isDirectory(modelDir)) {
                        continue;
                    }
                    try (Stream<Path> paths = Files.walk(modelDir)) {
                        List<Path> files = paths.filter(Files::isDirectory).sorted().toList();
                        for (Path e : files) {
                            GGUFModel model = this.handleDirectory(e);
                            if (model != null) this.list.add(model);
                        }
                    } catch (IOException e) {
                        e.printStackTrace();
                    }
                }
                List<Map<String, Object>> persisted = this.configManager.loadModelsConfigCached();
                Map<String, String> aliasMap = new HashMap<>();
                Map<String, Boolean> favouriteMap = new HashMap<>();
                for (Map<String, Object> rec : persisted) {
                    if (rec == null) continue;
                    Object id = rec.get("modelId");
                    if (id == null) continue;
                    String modelId = String.valueOf(id);
                    Object alias = rec.get("alias");
                    if (alias != null) {
                        String a = String.valueOf(alias);
                        if (!a.isEmpty()) aliasMap.put(modelId, a);
                    }
                    Object fav = rec.get("favourite");
                    if (fav != null) {
                        boolean v;
                        if (fav instanceof Boolean) {
                            v = (Boolean) fav;
                        } else {
                            v = Boolean.parseBoolean(String.valueOf(fav));
                        }
                        favouriteMap.put(modelId, v);
                    }
                }
                for (GGUFModel m : this.list) {
                    String alias = aliasMap.get(m.getModelId());
                    if (alias != null && !alias.isEmpty()) {
                        m.setAlias(alias);
                    }
                    Boolean fav = favouriteMap.get(m.getModelId());
                    if (fav != null) {
                        m.setFavourite(fav);
                    }
                }
            }
            // 如果集合不是空的，就直接返回。
            else {
                return this.list;
            }
        }
        return this.list;
    }

    /**
     * 	处理这个路径的文件夹，找到可用的GGUF文件。
     * 	使用GGUFBundle来处理文件分组和识别
     * @param path
     * @return
     */
	private synchronized GGUFModel handleDirectory(Path path) {
		File dir = path.toFile();
		if (dir.getName().startsWith("."))
			return null;

		if (dir == null || !dir.isDirectory()) {
			System.err.println("Invalid directory: " + path);
			return null;
		}
		
		File[] files = dir.listFiles((d, name) -> name.toLowerCase().endsWith(".gguf"));
		if (files == null || files.length == 0) {
			// System.err.println("No GGUF files found in directory: " + path);
			return null;
		}

		// 寻找最佳的种子文件来初始化GGUFBundle
		File seedFile = null;
		
		// 1. 尝试找到分卷的第一卷 (匹配 *-00001-of-*.gguf)
		for(File f : files) {
			String name = f.getName().toLowerCase();
			if(name.matches(".*-00001-of-\\d{5}\\.gguf$")) {
				seedFile = f;
				break;
			}
		}
		
		// 2. 如果没找到明确的第一卷，找一个不含mmproj的文件
		if(seedFile == null) {
			for(File f : files) {
				String name = f.getName().toLowerCase();
				if(!name.contains("mmproj")) {
					seedFile = f;
					break;
				}
			}
		}
		
		// 3. 实在不行，就用第一个文件
		if(seedFile == null && files.length > 0) {
			seedFile = files[0];
		}
		
		if(seedFile == null) return null;
		
		try {
			GGUFBundle bundle = new GGUFBundle(seedFile);
			
			GGUFModel model = new GGUFModel(dir.getName(), dir.getAbsolutePath());
			model.setAlias(dir.getName());
			
			// 处理主模型文件
			File primaryFile = bundle.getPrimaryFile();
			if(primaryFile != null && primaryFile.exists()) {
				GGUFMetaData md = GGUFMetaData.readFile(primaryFile);
				model.setPrimaryModel(md);
				// 将主模型元数据也添加到列表中，保持兼容性
				model.addMetaData(md);
			}
			
			// 处理mmproj文件
			File mmprojFile = bundle.getMmprojFile();
			if(mmprojFile != null && mmprojFile.exists()) {
				GGUFMetaData md = GGUFMetaData.readFile(mmprojFile);
				model.setMmproj(md);
				model.addMetaData(md);
			}
			
			// 优化：不再读取所有分卷文件的元数据
			// 分卷文件的元数据通常与主文件相同，或者只包含张量信息
			// 逐个读取会导致严重的IO性能问题
			/*
			List<File> splitFiles = bundle.getSplitFiles();
			if(splitFiles != null) {
				for(File f : splitFiles) {
					if(f.exists()) {
						GGUFMetaData md = GGUFMetaData.readFile(f);
						model.addMetaData(md);
					}
				}
			}
			*/
			
			model.setSize(bundle.getTotalFileSize());
			
			// 如果没有PrimaryModel，尝试从metaDataList中找一个
			if(model.getPrimaryModel() == null && !model.getMetaDataList().isEmpty()) {
				for(GGUFMetaData md : model.getMetaDataList()) {
					if("model".equals(md.getStringValue("general.type"))) {
						model.setPrimaryModel(md);
						break;
					}
				}
			}
			
			return model;
			
		} catch (Exception e) {
			System.err.println("处理目录失败 " + path + ": " + e.getMessage());
			return null;
		}
	}

	/**
	 *
	 * @param modelId
	 * @return
	 */
	public GGUFModel findModelById(String modelId) {
		for(GGUFModel e : this.list) {
			if(e.getModelId().equals(modelId))
				return e;
		}
		return null;
	}
	
	/**
	 * 获取下一个可用端口
	 * 使用PortChecker工具类检查端口是否真正可用
	 * @return 下一个可用端口号
	 */
	private synchronized int getNextAvailablePort() {
		int candidatePort = this.portCounter.get();
		try {
			// 使用PortChecker查找下一个可用端口
			int availablePort = PortChecker.findNextAvailablePort(candidatePort);
			
			// 更新端口计数器，确保下次从更高的端口开始
			this.portCounter.set(availablePort + 1);
			
			return availablePort;
		} catch (IllegalStateException e) {
			// 如果在有效范围内找不到可用端口，回退到原来的简单递增方式
			// 并打印警告信息
			System.err.println("警告: 无法找到可用端口，回退到简单递增方式。错误信息: " + e.getMessage());
			return this.portCounter.getAndIncrement();
		}
	}
	
	/**
	 * 获取已加载的模型进程列表
	 * @return 已加载的模型进程列表
	 */
	public Map<String, LlamaCppProcess> getLoadedProcesses() {
		return new HashMap<>(this.loadedProcesses);
	}
	
	/**
	 * 	获取第一个已经加载的模型的名字。
	 * @return
	 */
	public String getFirstModelName() {
		if (this.loadedProcesses.isEmpty()) {
			return null;
		}
		Map.Entry<String, LlamaCppProcess> firstEntry = this.loadedProcesses.entrySet().iterator().next();
		return firstEntry.getKey();
	}
	
	/**
	 * 	获取指定模型的启动参数。
	 * @param modelId
	 * @return
	 */
	public String getModelStartCmd(String modelId) {
		LlamaCppProcess process = this.loadedProcesses.get(modelId);
		if(process == null) return "";
		return process.getCmd();
	}
	
	/**
	 * 获取模型对应的端口
	 * @param modelId 模型ID
	 * @return 端口号，如果模型未加载则返回null
	 */
	public Integer getModelPort(String modelId) {
		return this.modelPorts.get(modelId);
	}
	
	/**
	 * 停止并移除已加载的模型
	 * @param modelId 模型ID
	 * @return 是否成功停止
	 */
	public synchronized boolean stopModel(String modelId) {
		LlamaCppProcess process = this.loadedProcesses.get(modelId);
		if (process != null) {
			boolean stopped = process.stop();
			if (stopped) {
				this.loadedProcesses.remove(modelId);
				this.modelPorts.remove(modelId);
			}
			return stopped;
		}
		return false;
	}
	
	/**
	 * 	检查指定ID的模型是否处于加载状态。
	 * @param modelId
	 * @return
	 */
	public boolean isLoading(String modelId) {
		synchronized (this.loadingModels) {
			return this.loadingModels.contains(modelId);
		}
	}
	
//	/**
//	 * 异步加载指定的模型
//	 *
//	 * @param modelId 模型ID
//	 * @param ctxSize 上下文大小
//	 * @param batchSize 批处理大小
//	 * @param ubatchSize 微批处理大小
//	 * @param noMmap 是否禁用内存映射
//	 * @param mlock 是否锁定内存
//	 * @return 是否成功启动加载任务
//	 */
//    public synchronized boolean loadModelAsync(String modelId, ModelLaunchOptions options) {
//
//        Map<String, Object> launchConfig = options.toConfigMap();
//        this.configManager.saveLaunchConfig(modelId, launchConfig);
//		
//		// 检查模型是否已经加载
//		if (this.loadedProcesses.containsKey(modelId)) {
//			System.err.println("模型 " + modelId + " 已经加载");
//			// 发送WebSocket事件通知模型已加载
//			LlamaServer.sendModelLoadEvent(modelId, false, "模型已经加载");
//			return false;
//		}
//		
//		// 查找指定的模型
//		GGUFModel targetModel = this.findModelById(modelId);
//		
//        if (targetModel == null) {
//            System.err.println("未找到ID为 " + modelId + " 的模型");
//            // 发送WebSocket事件通知模型未找到
//            LlamaServer.sendModelLoadEvent(modelId, false, "未找到ID为 " + modelId + " 的模型");
//            return false;
//        }
//
//        if (options.llamaBinPath == null || options.llamaBinPath.trim().isEmpty()) {
//            LlamaServer.sendModelLoadEvent(modelId, false, "未提供llamaBinPath");
//            return false;
//        }
//		// 如果这个模型已经在加载中 
//		synchronized (this.loadingModels) {
//			if(this.loadingModels.contains(targetModel.getModelId())) {
//				LlamaServer.sendModelLoadEvent(modelId, false, "该模型正在加载中");
//				return false;
//			}
//		}
//        this.executorService.submit(() -> {
//            this.loadModelInBackground(modelId, targetModel, options);
//        });
//		
//		return true; // 表示成功提交加载任务
//	}

	public synchronized boolean loadModelAsyncFromCmd(String modelId, String llamaBinPath, List<String> device, Integer mg, String cmd, String chatTemplateFilePath) {
		Map<String, Object> launchConfig = new HashMap<>();
		launchConfig.put("llamaBinPath", llamaBinPath);
		launchConfig.put("device", device);
		launchConfig.put("mg", mg);
		launchConfig.put("cmd", cmd);
		if (chatTemplateFilePath != null && !chatTemplateFilePath.trim().isEmpty()) {
			launchConfig.put("chatTemplateFile", chatTemplateFilePath);
		}
		this.configManager.saveLaunchConfig(modelId, launchConfig);

		if (this.loadedProcesses.containsKey(modelId)) {
			LlamaServer.sendModelLoadEvent(modelId, false, "模型已经加载");
			return false;
		}

		GGUFModel targetModel = this.findModelById(modelId);
		if (targetModel == null) {
			LlamaServer.sendModelLoadEvent(modelId, false, "未找到ID为 " + modelId + " 的模型");
			return false;
		}

		if (llamaBinPath == null || llamaBinPath.trim().isEmpty()) {
			LlamaServer.sendModelLoadEvent(modelId, false, "未提供llamaBinPath");
			return false;
		}

		synchronized (this.loadingModels) {
			if (this.loadingModels.contains(targetModel.getModelId())) {
				LlamaServer.sendModelLoadEvent(modelId, false, "该模型正在加载中");
				return false;
			}
		}

		final String cmdSafe = cmd == null ? "" : cmd.trim();
		final String binSafe = llamaBinPath.trim();
		final List<String> devSafe = device;
		final Integer mgSafe = mg;
		final String chatTemplateFileSafe = chatTemplateFilePath == null ? "" : chatTemplateFilePath;

		this.executorService.submit(() -> {
			this.loadModelInBackgroundFromCmd(modelId, targetModel, binSafe, devSafe, mgSafe, cmdSafe, chatTemplateFileSafe);
		});
		return true;
	}
	
//	/**
//	 * 在后台线程中执行模型加载
//	 */
//    private synchronized void loadModelInBackground(String modelId, GGUFModel targetModel, ModelLaunchOptions options) {
//
//        // 获取下一个可用端口
//        int port = this.getNextAvailablePort();
//
//        List<String> command = options.toCmdLine(targetModel, port);
//
//        // 构建完整的命令字符串
//        String commandStr = String.join(" ", command);
//		
//		// 创建并启动LlamaCppProcess
//		String processName = "llama-server-" + modelId;
//		LlamaCppProcess process = new LlamaCppProcess(processName, commandStr);
//		
//		System.out.println("启动命令：" + commandStr);
//		
//		// 使用CountDownLatch来同步等待加载结果
//		CountDownLatch latch = new CountDownLatch(1);
//		AtomicBoolean loadSuccess = new AtomicBoolean(false);
//		
//		// 设置输出处理器，接受llamacpp运行状态，然后判断特定的内容。
//        process.setOutputHandler(line -> {
//            //	判断是否加载成功。
//            //	1.这是成功了
//            if(line.contains("srv  update_slots: all slots are idle")) {
//                loadSuccess.set(true);
//                latch.countDown();
//            }
//            //	2.这是失败了
//            if(line.contains("main: exiting due to model loading error")) {
//                loadSuccess.set(false);
//                latch.countDown();
//            }
//            //	3.检测进程异常终止
//            if(line.contains("Inferior") && line.contains("detached")) {
//                // 检测到进程异常终止，如 [Inferior 1 (process 6869) detached]
//                System.err.println("检测到模型进程异常终止: " + line);
//                
//                // 设置加载失败状态
//                loadSuccess.set(false);
//                
//                // 从已加载进程列表中移除
//                this.loadedProcesses.remove(modelId);
//                this.modelPorts.remove(modelId);
//                
//                // 通过WebSocket广播模型停止事件
//                LlamaServer.sendModelStopEvent(modelId, false, "模型进程异常终止: " + line);
//                
//                // 唤醒等待的线程
//                latch.countDown();
//            }
//            //	4.检测到参数错误
//            if(line.startsWith("error")) {
//            	 System.err.println("检测到模型进程异常终止: " + line);
//                 // 设置加载失败状态
//                 loadSuccess.set(false);
//                 
//                 // 从已加载进程列表中移除
//                 this.loadedProcesses.remove(modelId);
//                 this.modelPorts.remove(modelId);
//                 
//                 // 通过WebSocket广播模型停止事件
//                 //LlamaServer.sendModelStopEvent(modelId, false, "模型启动失败: " + line);
//                 
//                 // 唤醒等待的线程
//                 latch.countDown();
//            }
//        });
//		
//		// 启动进程
//		boolean started = process.start();
//		if (!started) {
//			System.err.println("启动模型 " + modelId + " 失败");
//			// 发送WebSocket事件通知启动失败
//			LlamaServer.sendModelLoadEvent(modelId, false, "启动模型进程失败");
//			return;
//		}else {
//			// 设置模型的状态为启动中
//			synchronized (this.loadingModels) {
//				this.loadingModels.add(targetModel.getModelId());
//			}
//		}
//		
//		// 等待进程加载完成，超时时间10分钟
//		try {
//			boolean timeout = !latch.await(10, TimeUnit.MINUTES);
//			
//			if (timeout) {
//				System.err.println("加载模型 " + modelId + " 超时");
//				// 停止进程
//				process.stop();
//				// 发送WebSocket事件通知加载超时
//				LlamaServer.sendModelLoadEvent(modelId, false, "模型加载超时");
//				return;
//			}
//			
//			if (loadSuccess.get()) {
//				// 保存进程信息
//				this.loadedProcesses.put(modelId, process);
//				this.modelPorts.put(modelId, port);
//				System.out.println("成功启动模型 " + modelId + "，端口: " + port + "，PID: " + process.getPid());
//				// 发送WebSocket事件通知加载成功
//				LlamaServer.sendModelLoadEvent(modelId, true, "模型加载成功，端口: " + port);
//			} else {
//				System.err.println("加载模型 " + modelId + " 失败");
//				// 停止进程
//				process.stop();
//				// 发送WebSocket事件通知加载失败
//				LlamaServer.sendModelLoadEvent(modelId, false, "模型加载失败");
//			}
//		} catch (InterruptedException e) {
//			System.err.println("等待模型加载时被中断: " + e.getMessage());
//			Thread.currentThread().interrupt();
//			// 停止进程
//			process.stop();
//			// 发送WebSocket事件通知加载被中断
//			LlamaServer.sendModelLoadEvent(modelId, false, "模型加载被中断");
//		}finally {
//			synchronized (this.loadingModels) {
//				this.loadingModels.remove(targetModel.getModelId());
//			}
//		}
//	}

	private synchronized void loadModelInBackgroundFromCmd(String modelId, GGUFModel targetModel, String llamaBinPath, List<String> device,
			Integer mg, String cmd, String chatTemplateFilePath) {
		int port = this.getNextAvailablePort();

		String commandStr = buildCommandStr(targetModel, port, llamaBinPath, device, mg, cmd, chatTemplateFilePath);

		String processName = "llama-server-" + modelId;
		LlamaCppProcess process = new LlamaCppProcess(processName, commandStr);

		System.out.println("启动命令：" + commandStr);

		CountDownLatch latch = new CountDownLatch(1);
		AtomicBoolean loadSuccess = new AtomicBoolean(false);

		process.setOutputHandler(line -> {
			if (line.contains("srv  update_slots: all slots are idle")) {
				loadSuccess.set(true);
				latch.countDown();
			}
			if (line.contains("main: exiting due to model loading error")) {
				loadSuccess.set(false);
				latch.countDown();
			}
			if (line.contains("Inferior") && line.contains("detached")) {
				System.err.println("检测到模型进程异常终止: " + line);
				loadSuccess.set(false);
				this.loadedProcesses.remove(modelId);
				this.modelPorts.remove(modelId);
				LlamaServer.sendModelStopEvent(modelId, false, "模型进程异常终止: " + line);
				latch.countDown();
			}
			if (line.startsWith("error")) {
				System.err.println("检测到模型进程异常终止: " + line);
				loadSuccess.set(false);
				this.loadedProcesses.remove(modelId);
				this.modelPorts.remove(modelId);
				latch.countDown();
			}
		});

		boolean started = process.start();
		if (!started) {
			LlamaServer.sendModelLoadEvent(modelId, false, "启动模型进程失败");
			return;
		} else {
			synchronized (this.loadingModels) {
				this.loadingModels.add(targetModel.getModelId());
			}
		}

		try {
			boolean timeout = !latch.await(10, TimeUnit.MINUTES);
			if (timeout) {
				process.stop();
				LlamaServer.sendModelLoadEvent(modelId, false, "模型加载超时");
				return;
			}

			if (loadSuccess.get()) {
				this.loadedProcesses.put(modelId, process);
				this.modelPorts.put(modelId, port);
				LlamaServer.sendModelLoadEvent(modelId, true, "模型加载成功，端口: " + port);
			} else {
				process.stop();
				LlamaServer.sendModelLoadEvent(modelId, false, "模型加载失败");
			}
		} catch (InterruptedException e) {
			Thread.currentThread().interrupt();
			process.stop();
			LlamaServer.sendModelLoadEvent(modelId, false, "模型加载被中断");
		} finally {
			synchronized (this.loadingModels) {
				this.loadingModels.remove(targetModel.getModelId());
			}
		}
	}

	private static String buildCommandStr(GGUFModel targetModel, int port, String llamaBinPath, List<String> device, Integer mg, String cmd, String chatTemplateFilePath) {
		StringBuilder sb = new StringBuilder();

		String exe = llamaBinPath + File.separator + "llama-server";
		sb.append(quoteIfNeeded(exe));

		sb.append(" -m ");
		String modelFile = targetModel.getPath() + "/" + targetModel.getPrimaryModel().getFileName();
		sb.append(quoteIfNeeded(modelFile));

		sb.append(" --port ");
		sb.append(port);

		if (targetModel.getMmproj() != null && !cmdHasFlag(cmd, "--mmproj") && !cmdHasFlag(cmd, "--no-mmproj")) {
			sb.append(" --mmproj ");
			String mmprojFile = targetModel.getPath() + "/" + targetModel.getMmproj().getFileName();
			sb.append(quoteIfNeeded(mmprojFile));
		}

		if (device != null && !device.isEmpty()) {
			if (device.size() == 1) {
				if (!"All".equals(device.get(0))) {
					sb.append(" -sm none -dev ");
					sb.append(quoteIfNeeded(device.get(0)));
					sb.append(" -mg ");
					sb.append(mg != null ? String.valueOf(mg) : "0");
				}
			} else {
				sb.append(" -dev ");
				sb.append(quoteIfNeeded(String.join(",", device)));
			}
		}

		if (cmd != null && !cmd.trim().isEmpty()) {
			sb.append(' ');
			sb.append(cmd.trim());
		}
		if (chatTemplateFilePath != null && !chatTemplateFilePath.trim().isEmpty() && !cmdHasFlag(cmd, "--chat-template-file") && !cmdHasFlag(cmd, "--chat-template")) {
			sb.append(" --chat-template-file ");
			sb.append(quoteIfNeeded(chatTemplateFilePath.trim()));
		}

		if (!cmdHasFlag(cmd, "--no-webui") && !cmdHasFlag(cmd, "--webui")) {
			sb.append(" --no-webui");
		}
		if (!cmdHasFlag(cmd, "--metrics")) {
			sb.append(" --metrics");
		}
		if (!cmdHasFlag(cmd, "--slot-save-path")) {
			sb.append(" --slot-save-path ");
			sb.append(quoteIfNeeded(LlamaServer.getCachePath().toFile().getAbsolutePath()));
		}
		if (!cmdHasFlag(cmd, "--cache-ram")) {
			sb.append(" --cache-ram -1");
		}

		return sb.toString().trim();
	}

	private static boolean cmdHasFlag(String cmd, String flag) {
		if (cmd == null || flag == null || flag.trim().isEmpty()) {
			return false;
		}
		String f = flag.trim();
		String s = " " + cmd.trim() + " ";
		return s.contains(" " + f + " ") || s.contains(" " + f + "=");
	}

	private static String quoteIfNeeded(String s) {
		if (s == null) {
			return "";
		}
		String t = s;
		boolean needs = false;
		for (int i = 0; i < t.length(); i++) {
			char c = t.charAt(i);
			if (Character.isWhitespace(c) || c == '"') {
				needs = true;
				break;
			}
		}
		if (!needs) {
			return t;
		}
		return "\"" + t.replace("\"", "\\\"") + "\"";
	}
	
	/**
		* 停止所有模型进程并退出Java进程
		*/
	public synchronized void shutdownAll() {
		System.out.println("开始停止所有模型进程...");
		
		// 获取所有已加载的进程
		Map<String, LlamaCppProcess> processes = new HashMap<>(this.loadedProcesses);
		
		// 停止所有模型进程
		for (Map.Entry<String, LlamaCppProcess> entry : processes.entrySet()) {
			String modelId = entry.getKey();
			LlamaCppProcess process = entry.getValue();
			
			System.out.println("正在停止模型进程: " + modelId);
			boolean stopped = process.stop();
			if (stopped) {
				System.out.println("成功停止模型进程: " + modelId);
			} else {
				System.err.println("停止模型进程失败: " + modelId);
			}
		}
		
		// 清空进程列表和端口映射
		this.loadedProcesses.clear();
		this.modelPorts.clear();
		
		// 关闭线程池
		this.executorService.shutdown();
		
		System.out.println("所有模型进程已停止，即将退出Java进程");
		
		// 退出Java进程
		System.exit(0);
	}
	
	
	//##########################################################################################
	
	
	/**
	 * 	获取Slots信息
	 * @param modelId
	 * @return
	 */
	public ApiResponse handleModelSlotsGet(String modelId) {
		try {
			if (!this.getLoadedProcesses().containsKey(modelId)) {
				return ApiResponse.error("模型未加载: " + modelId);
			}
			Integer port = this.getModelPort(modelId);
			if (port == null) {
				return ApiResponse.error("未找到模型端口: " + modelId);
			}
			String targetUrl = String.format("http://localhost:%d/slots", port);
			URL url = URI.create(targetUrl).toURL();
			HttpURLConnection connection = (HttpURLConnection) url.openConnection();
			connection.setRequestMethod("GET");
			connection.setConnectTimeout(30000);
			connection.setReadTimeout(30000);
			int responseCode = connection.getResponseCode();
			String responseBody;
			if (responseCode >= 200 && responseCode < 300) {
				try (BufferedReader br = new BufferedReader(new InputStreamReader(connection.getInputStream(), StandardCharsets.UTF_8))) {
					StringBuilder sb = new StringBuilder();
					String line;
					while ((line = br.readLine()) != null) {
						sb.append(line);
					}
					responseBody = sb.toString();
				}
				Object parsed = gson.fromJson(responseBody, Object.class);
				Map<String, Object> data = new HashMap<>();
				data.put("modelId", modelId);
				data.put("slots", parsed);
				
				connection.disconnect();
				return ApiResponse.success(data);
			} else {
				try (BufferedReader br = new BufferedReader(new InputStreamReader(connection.getErrorStream(), StandardCharsets.UTF_8))) {
					StringBuilder sb = new StringBuilder();
					String line;
					while ((line = br.readLine()) != null) {
						sb.append(line);
					}
					responseBody = sb.toString();
				}
				connection.disconnect();
				return ApiResponse.error("获取slots失败: " + responseBody);
			}
		} catch (Exception e) {
			LOGGER.error("获取slots时发生错误", e);
			return ApiResponse.error("获取slots失败: " + e.getMessage());
		}
	}
	
	
	
	
	/**
	 * 	
	 * @param modelId
	 * @param slot
	 * @param fileName
	 * @return
	 */
	public ApiResponse handleModelSlotsSave(String modelId, int slot, String fileName) {
		HttpURLConnection connection = null;
		try {
			// 两个判断
			if (!this.getLoadedProcesses().containsKey(modelId)) {
				return ApiResponse.error("模型未加载: " + modelId);
			}
			Integer port = this.getModelPort(modelId);
			if (port == null) {
				return ApiResponse.error("未找到模型端口: " + modelId);
			}
			
			
			String endpoint = String.format("/slots/%d?action=save", slot);
			String targetUrl = String.format("http://localhost:%d%s", port, endpoint);
			URL url = URI.create(targetUrl).toURL();
			connection = (HttpURLConnection) url.openConnection();
			connection.setRequestMethod("POST");
			connection.setDoOutput(true);
			connection.setRequestProperty("Content-Type", "application/json; charset=UTF-8");
			connection.setConnectTimeout(36000 * 1000);
			connection.setReadTimeout(36000 * 1000);
			JsonObject body = new JsonObject();
			body.addProperty("filename", fileName);
			byte[] input = body.toString().getBytes(StandardCharsets.UTF_8);
			try (OutputStream os = connection.getOutputStream()) {
				os.write(input, 0, input.length);
			}
			int responseCode = connection.getResponseCode();
			String responseBody;
			if (responseCode >= 200 && responseCode < 300) {
				try (BufferedReader br = new BufferedReader(
						new InputStreamReader(connection.getInputStream(), StandardCharsets.UTF_8))) {
					StringBuilder sb = new StringBuilder();
					String line;
					while ((line = br.readLine()) != null) {
						sb.append(line);
					}
					responseBody = sb.toString();
				}
				Object parsed = gson.fromJson(responseBody, Object.class);
				Map<String, Object> data = new HashMap<>();
				data.put("modelId", modelId);
				data.put("result", parsed);
				connection.disconnect();
				return ApiResponse.success(data);
			} else {
				try (BufferedReader br = new BufferedReader(
						new InputStreamReader(connection.getErrorStream(), StandardCharsets.UTF_8))) {
					StringBuilder sb = new StringBuilder();
					String line;
					while ((line = br.readLine()) != null) {
						sb.append(line);
					}
					responseBody = sb.toString();
				}
				connection.disconnect();
				return ApiResponse.error("保存slot失败: " + responseBody);
			}
		} catch (Exception e) {
			LOGGER.error("保存slot缓存时发生错误", e);
			return ApiResponse.error("保存slot失败: " + e.getMessage());
		}
	}
	
	/**
	 * 	
	 * @param modelId
	 * @param slot
	 * @param fileName
	 * @return
	 */
	public ApiResponse handleModelSlotsLoad(String modelId, int slot, String fileName) {
		try {
			LlamaServerManager manager = LlamaServerManager.getInstance();
			if (!manager.getLoadedProcesses().containsKey(modelId)) {
				return ApiResponse.error("模型未加载: " + modelId);
			}
			Integer port = manager.getModelPort(modelId);
			if (port == null) {
				return ApiResponse.error("未找到模型端口: " + modelId);
			}
			String endpoint = String.format("/slots/%d?action=restore", slot);
			String targetUrl = String.format("http://localhost:%d%s", port, endpoint);
			URL url = URI.create(targetUrl).toURL();
			HttpURLConnection connection = (HttpURLConnection) url.openConnection();
			connection.setRequestMethod("POST");
			connection.setDoOutput(true);
			connection.setRequestProperty("Content-Type", "application/json; charset=UTF-8");
			connection.setConnectTimeout(36000 * 1000);
			connection.setReadTimeout(36000 * 1000);
			JsonObject body = new JsonObject();
			body.addProperty("filename", fileName);
			byte[] input = body.toString().getBytes(StandardCharsets.UTF_8);
			try (OutputStream os = connection.getOutputStream()) {
				os.write(input, 0, input.length);
			}
			int responseCode = connection.getResponseCode();
			String responseBody;
			if (responseCode >= 200 && responseCode < 300) {
				try (BufferedReader br = new BufferedReader(new InputStreamReader(connection.getInputStream(), StandardCharsets.UTF_8))) {
					StringBuilder sb = new StringBuilder();
					String line;
					while ((line = br.readLine()) != null) {
						sb.append(line);
					}
					responseBody = sb.toString();
				}
				Object parsed = gson.fromJson(responseBody, Object.class);
				Map<String, Object> data = new HashMap<>();
				data.put("modelId", modelId);
				data.put("result", parsed);
				
				connection.disconnect();
				return ApiResponse.success(data);
			} else {
				try (BufferedReader br = new BufferedReader(new InputStreamReader(connection.getErrorStream(), StandardCharsets.UTF_8))) {
					StringBuilder sb = new StringBuilder();
					String line;
					while ((line = br.readLine()) != null) {
						sb.append(line);
					}
					responseBody = sb.toString();
				}
				connection.disconnect();
				return ApiResponse.error("加载slot失败: " + responseBody);
			}
		} catch (Exception e) {
			LOGGER.error("加载slot缓存时发生错误", e);
			return ApiResponse.error("加载slot失败: " + e.getMessage());
		}
	}
	
	
	/**
	 * 	查找可用的计算设备
	 * @param llamaBinPath
	 * @return
	 */
	public List<String> handleListDevices(String llamaBinPath) {
		List<String> list = new ArrayList<>(8);
		
		String executableName = "llama-bench";
		// 拼接完整命令路径
		String command = llamaBinPath.trim();
		command += File.separator;
		
		command += executableName + " --list-devices";
		
		// 执行命令
		CommandLineRunner.CommandResult result = CommandLineRunner.execute(command, 30);
		// 根据list device的返回结果。拼凑设备
		String output = result.getOutput();
		if(output.contains("Available devices")) {
			String[] lines = output.split("\n");
			for(int i = 1; i < lines.length; i++) {
				list.add(lines[i]);
			}
		}
		return list;
	}
	
	/**
	 * 	调用llama-fit-params
	 * @param llamaBinPath
	 * @param devices
	 */
	public void handleFitParam(String llamaBinPath, List<String> devices) {
		
		
		
		return;
	}
	
	/**
	 * 	用户估算显存。
	 * @param llamaBinPath
	 * @param modelId
	 * @param cmd
	 * @return
	 */
	public String handleFitParam(String llamaBinPath, String modelId, List<String> cmd) {
		String[] keysParam = {"--ctx-size", "--flash-attn", "--batch-size", "--ubatch-size", "--parallel", "--kv-unified", "--cache-type-k", "--cache-type-v"};
		Map<String, String> cmdMap = new HashMap<>();
		for(int i = 0; i < cmd.size(); i++) {
			String param = cmd.get(i);
			if(param.startsWith("--")) {
				if(!cmd.get(i + 1).startsWith("--")) {
					cmdMap.put(param, cmd.get(i + 1));
					i += 1;
				}else {
					cmdMap.put(param, param);
				}
			}
		}
		GGUFModel model = this.findModelById(modelId);
		if(model == null) return null;
		
		String executableName = "llama-fit-params";
		// 拼接完整命令路径
		String command = llamaBinPath.trim() + File.separator + executableName;
		command += " --model " + model.getPrimaryModel().getFilePath();
		
		for(String key : keysParam) {
			// 如果有这个参数
			if(cmdMap.containsKey(key)) {
				String value = cmdMap.get(key);
				if(key.equals(value)) {
					command += key;
				}else {
					command += " " + key + " " + value;
				}
			}
		}
		
		// 执行命令
		CommandLineRunner.CommandResult result = CommandLineRunner.execute(command, 30);
		String output = result.getError();
		// 提取第一个数值
		Pattern numberPattern = Pattern.compile("llama_params_fit_impl: projected to use (\\d+) MiB");
		Matcher numberMatcher = numberPattern.matcher(output);
		if (numberMatcher.find()) {
		    String value = numberMatcher.group(1);
		    return value;
		}
		return null;
	}
	
}
